{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPQFN0qQNFmK9qRB5U1OHMM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uroojfatima18/AI-Agents/blob/main/context_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task: Build a Dynamic Greeting System Using OpenAI SDK"
      ],
      "metadata": {
        "id": "ElI0RWSiKu6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Build a system using the OpenAI SDK where the agent can greet the user dynamically using their name and age.\n",
        "\n",
        "The function should be integrated with the RunContextWrapper class, and the agent must be able to access the user's context without writing a new function each time.\n",
        "\n",
        "The agent should automatically pull the user information (name and age) from the context object, making the system reusable and scalable."
      ],
      "metadata": {
        "id": "NGyLSi7NK75H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqyQ__94Bgfn",
        "outputId": "a3fbb0c6-8452-4b6f-cba0-c69376f9cc9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/120.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.2/120.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.4/720.4 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "UkuQgi99B3g_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic  import BaseModel\n",
        "from agents import AsyncOpenAI,OpenAIChatCompletionsModel,RunConfig\n",
        "from google.colab import userdata\n",
        "\n",
        "gemini_api_key = userdata.get(\"GEMINI_API_KEY\")"
      ],
      "metadata": {
        "id": "D_4YdSfyB5GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the API key is present; if not, raise an error\n",
        "if not gemini_api_key:\n",
        "    raise ValueError(\"GEMINI_API_KEY is not set. Please ensure it is defined in your .env file.\")\n",
        "\n",
        "#Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=external_client\n",
        ")"
      ],
      "metadata": {
        "id": "g4bOGgwQB_JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import set_default_openai_client, set_tracing_disabled\n",
        "set_default_openai_client(external_client)\n",
        "set_tracing_disabled(True)"
      ],
      "metadata": {
        "id": "VABdqgrRCJR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from dataclasses import dataclass\n",
        "from agents import Agent, RunContextWrapper, Runner, function_tool\n",
        "\n",
        "@dataclass\n",
        "class UserInfo():\n",
        "  name:str\n",
        "  age:int\n",
        "\n",
        "@function_tool\n",
        "async def  greetuser(context:RunContextWrapper[UserInfo]):\n",
        "  name=context.context.name\n",
        "  age=context.context.age\n",
        "  return f\"Hello {name}. A young {age} year's old girl .Welcome back!\"\n",
        "\n",
        "\n",
        "\n",
        "async def main():\n",
        "  userinfo=UserInfo(name=\" Urooj fatima\" ,age =\"19\")\n",
        "\n",
        "  agent = Agent[UserInfo](\n",
        "        name=\"Assistant\",\n",
        "        tools=[greetuser],\n",
        "        model=model,\n",
        "        instructions=\n",
        "        \"Always use the greetuser tool to greet the user. \"\n",
        "        \"Make sure to warmly welcome them to Panaversity using their age and name\"\n",
        "        )\n",
        "\n",
        "  result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"hello\",\n",
        "        context=userinfo,\n",
        "    )\n",
        "  print(\"Agent response:\",result)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNWiQ8uyCQiZ",
        "outputId": "344721bc-1cfa-4050-fdc6-f98a288f083c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent response: RunResult:\n",
            "- Last agent: Agent(name=\"Assistant\", ...)\n",
            "- Final output (str):\n",
            "    Hello Urooj fatima. A young 19 year's old girl .Welcome back! I hope you're ready to dive into some exciting learning experiences here at Panaversity!\n",
            "- 3 new item(s)\n",
            "- 2 raw response(s)\n",
            "- 0 input guardrail result(s)\n",
            "- 0 output guardrail result(s)\n",
            "(See `RunResult` for more details)\n"
          ]
        }
      ]
    }
  ]
}