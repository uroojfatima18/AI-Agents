{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOfj7dkf0NjMmkxFFU6Ci8B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uroojfatima18/AI-Agents/blob/main/streaming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U q openai-agents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7Hffv94W5062",
        "outputId": "3d51b211-b7aa-4689-ad50-7d98322d84e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting q\n",
            "  Downloading q-2.7-py2.py3-none-any.whl.metadata (811 bytes)\n",
            "Collecting openai-agents\n",
            "  Downloading openai_agents-0.0.15-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting griffe<2,>=1.5.6 (from openai-agents)\n",
            "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting mcp<2,>=1.8.0 (from openai-agents)\n",
            "  Downloading mcp-1.9.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: openai>=1.76.0 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (1.78.1)\n",
            "Requirement already satisfied: pydantic<3,>=2.10 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (2.11.4)\n",
            "Requirement already satisfied: requests<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (2.32.3)\n",
            "Collecting types-requests<3,>=2.0 (from openai-agents)\n",
            "  Downloading types_requests-2.32.0.20250515-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (4.13.2)\n",
            "Collecting colorama>=0.4 (from griffe<2,>=1.5.6->openai-agents)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: anyio>=4.5 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.8.0->openai-agents) (4.9.0)\n",
            "Collecting httpx-sse>=0.4 (from mcp<2,>=1.8.0->openai-agents)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.8.0->openai-agents) (0.28.1)\n",
            "Collecting pydantic-settings>=2.5.2 (from mcp<2,>=1.8.0->openai-agents)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting python-multipart>=0.0.9 (from mcp<2,>=1.8.0->openai-agents)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting sse-starlette>=1.6.1 (from mcp<2,>=1.8.0->openai-agents)\n",
            "  Downloading sse_starlette-2.3.5-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting starlette>=0.27 (from mcp<2,>=1.8.0->openai-agents)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting uvicorn>=0.23.1 (from mcp<2,>=1.8.0->openai-agents)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.76.0->openai-agents) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.76.0->openai-agents) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.76.0->openai-agents) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.76.0->openai-agents) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->mcp<2,>=1.8.0->openai-agents) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27->mcp<2,>=1.8.0->openai-agents) (0.16.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.5.2->mcp<2,>=1.8.0->openai-agents)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.23.1->mcp<2,>=1.8.0->openai-agents) (8.2.0)\n",
            "Downloading q-2.7-py2.py3-none-any.whl (10 kB)\n",
            "Downloading openai_agents-0.0.15-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mcp-1.9.0-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.1/125.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20250515-py3-none-any.whl (20 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading sse_starlette-2.3.5-py3-none-any.whl (10 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: q, uvicorn, types-requests, python-multipart, python-dotenv, httpx-sse, colorama, starlette, griffe, sse-starlette, pydantic-settings, mcp, openai-agents\n",
            "Successfully installed colorama-0.4.6 griffe-1.7.3 httpx-sse-0.4.0 mcp-1.9.0 openai-agents-0.0.15 pydantic-settings-2.9.1 python-dotenv-1.1.0 python-multipart-0.0.20 q-2.7 sse-starlette-2.3.5 starlette-0.46.2 types-requests-2.32.0.20250515 uvicorn-0.34.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from agents import Agent,Runner,AsyncOpenAI, OpenAIChatCompletionsModel, set_tracing_disabled\n",
        "from google.colab import userdata\n",
        "from openai.types.responses import ResponseTextDeltaEvent\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "-UspyfSj6Ex_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_api_key= userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "13eHWCUexBV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "external_client=AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "Model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=external_client,\n",
        ")\n",
        "\n",
        "set_tracing_disabled(disabled=True)"
      ],
      "metadata": {
        "id": "Utf05j8M-bo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Raw response event\n"
      ],
      "metadata": {
        "id": "_vw0r-A0_nb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from openai.types.responses import ResponseTextDeltaEvent\n",
        "from agents import Agent, Runner,AsyncOpenAI\n",
        "\n",
        "async def main():\n",
        "  agent=Agent(\n",
        "      name=\"HELPER\",\n",
        "      instructions= \"you are a helping assistant to help in user query\",\n",
        "      model=Model\n",
        "  )\n",
        "  result=Runner.run_streamed(agent , input = \"tell me  3joke\")\n",
        "\n",
        "  async for event in result.stream_events():\n",
        "     if  event.type ==\"raw_resonse_event\"  and isinstance(event.data ,ResponseTextDeltaEvent):\n",
        "      print(event.data.delta , end ='')\n",
        "\n",
        "  print(result.final_output)\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "r0gRr_A65v4i",
        "outputId": "522168d5-ed8f-4fea-a96a-fd2d8431d97b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here are 3 jokes for you:\n",
            "\n",
            "1.  Why don't scientists trust atoms?\n",
            "    Because they make up everything!\n",
            "\n",
            "2.  What do you call a lazy kangaroo?\n",
            "    Pouch potato!\n",
            "\n",
            "3.  Why did the scarecrow win an award?\n",
            "    Because he was outstanding in his field!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run item events and agent events"
      ],
      "metadata": {
        "id": "MPZoSifCRCQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import asyncio\n",
        "# from openai.types.responses import ResponseTextDeltaEvent\n",
        "from agents import Agent, Runner , ItemHelpers ,function_tool\n",
        "\n",
        "@function_tool\n",
        "def how_many_jokes():\n",
        "  return random.randint(1,10)\n",
        "\n",
        "async def main():\n",
        "  agent=Agent(\n",
        "      name=\"joker\",\n",
        "      instructions= \"First call the `how_many_jokes` tool, then tell that many jokes.\",\n",
        "      model=Model,\n",
        "      tools=[how_many_jokes]\n",
        "  )\n",
        "  result=Runner.run_streamed(agent , input = \"hellow\")\n",
        "\n",
        "  async for event  in result.stream_events():\n",
        "    if event.type==\"raw_reponse_event\":\n",
        "      continue\n",
        "\n",
        "    elif event.type ==\"agent_updated_streamed_event\":\n",
        "      print(f\"Agent updated: {event.new_agent.name}\")\n",
        "      continue\n",
        "\n",
        "    elif event.type ==\"run_item_streamed_event\":\n",
        "      if event.item.type==\"tool_call_item\":\n",
        "         print(f\"tool was called\")\n",
        "\n",
        "      elif event.type==\"tool_call_output_item\":\n",
        "        print(f\"tool called:{event.item.output}\")\n",
        "\n",
        "      elif event.type == \"message_output_item\":\n",
        "        print(f\"message output :\\n{ItemHelpers.text_message_output(event.item)}\")\n",
        "      else:\n",
        "          pass\n",
        "\n",
        "asyncio.run(main())\n",
        "\n"
      ],
      "metadata": {
        "id": "q3pBLvmt_OUb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}